# Быстрая оценка архитектуры и рекомендации (LDUP v4)

Ниже — сохранённая оценка достоверности/реализуемости архитектуры в `docs/project_v4`, а также рекомендации по быстрому старту и оптимизации парсинга юридических документов.

## Оценка достоверности и реализуемости

- **Сильная сторона**: чёткое разделение compile-time и runtime — реалистично и соответствует типичной схеме DSPy (оптимизаторы не запускаются на каждый документ). Внутри документации это консистентно.
- **Стек**: Pydantic + adaptix + loguru + hypothesis — реалистичный и практичный набор, даёт быстрый выигрыш по валидации, логированию и тестам.
- **Самообучение**: возможно, но дорого в разработке и требует качественной валидации, иначе риск «самообучения на шуме».
- **TCGR / CrossRef / HCO / графовая БД**: реализуемо, но это крупные подсистемы; для быстрого старта лучше упростить.
- **Оценки LLM‑стоимости/таймингов** выглядят оптимистично; реальный runtime зависит от длины документа, чанкинга и числа статей.

## Критические риски / пробелы

- **Нет формата обучающей разметки и метрик качества**. Без стабильной разметки GEPA/SIMBA/MiPROv2 будут давать нестабильные улучшения.
- **Парсинг PDF/WordML**: не описаны OCR/структурные стратегии — главный источник ошибок в юр. документах.
- **Источники (Консультант/Гарант)**: возможны юридические/лицензионные ограничения на доступ и выгрузку.
- **Rule‑store** может раздуваться и конфликтовать. Нужны дедупликация, приоритеты и аудит.
- **Экспорт AKN/LegalDocML‑RU**: требуется строгая XSD‑валидация (иначе риск некорректных файлов).

## Быстрый старт (MVP за 1–2 недели)

1) Ограничить входные форматы: **WordML (.docx) + plain text**, без PDF/OCR.
2) Реализовать **основной runtime**: ingest → структура → семантика → экспорт **JSON** (без графа и XML).
3) Ввести **минимальный rule‑set** на Pydantic (структурные и семантические правила), **без самообучения**.
4) Запустить **логирование и метрики** (loguru), собрать 20–50 реальных документов и получить baseline.
5) Добавить **один DSPy оптимизатор** (например, GEPA только для структуры), без SIMBA/MiPROv2.

## Оптимизация процесса парсинга

- **Сначала правила, потом LLM**: структуру лучше брать regex/эвристиками; LLM — только для сложных случаев.
- **Чанкинг по структуре**: сначала извлечь статьи/главы, затем обрабатывать их отдельно — снижает LLM‑нагрузку.
- **Кеширование на уровне блоков** (HCO cache) — после стабилизации структурного парсинга.
- **Параллельная семантика**: классифицировать статьи в пуле потоков с ограничениями rate‑limit LLM.
- **Регрессионный набор**: 30–50 «золотых» документов, иначе оптимизации и self‑improvement неконтролируемы.
- **Снижение LLM‑затрат**: кэшировать частые формулировки (в ФЗ много повторов), использовать локальные шаблоны.

## Что лучше урезать на старте

- Самообучение (оставить только сбор фидбека).
- TCGR и графовую БД (начать с JSON/SQLite).
- Экспорт в AKN/LegalDocML — позже, после стабилизации структуры.
