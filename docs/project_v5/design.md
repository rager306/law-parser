# Архитектурный дизайн LDUP v5

## 1. Концепция: Recursive Neuro-Symbolic Parser

LDUP v5 отказывается от парадигмы «загрузить всё в LLM» в пользу **рекурсивного построения графа знаний**.

### 1.1. RLM-патерн (Recursive Language Models)
Вместо плоского списка чанков, система строит иерархию «Кристаллов» (C³):
1.  **L0 (Project):** Метаданные закона (номер, дата, редакция).
2.  **L1 (Structure):** Краткое содержание глав.
3.  **L2 (Article):** Семантический «кристалл» конкретной статьи.
4.  **L3 (Link):** Связь (Change/Enforcement) между статьями.

**Источник:** [Alex Zhang et al. (arXiv:2512.24601)](https://arxiv.org/abs/2512.24601) — методология рекурсивного сжатия контекста.

### 1.2. Hybrid CPU Retrieval
Так как GPU недоступен, используется трехуровневый поиск:
*   **Exact Match:** SQLite FTS5 (статьи, пункты).
*   **Ranking:** RankBM25 (юридические термины).
*   **Semantic:** FastEmbed (ONNX) — легкие векторы для «смыслового» поиска коллизий.

## 2. Потоковый Ingester (WordML)

Используется `lxml.etree.iterparse` для обработки WordML КонсультантПлюс.

**Алгоритм:**
1.  Открывается поток к файлу.
2.  Ищутся теги `<w:p>`, помеченные стилем `ConsPlusTitle`.
3.  Текст накапливается в буфере до появления следующего заголовка.
4.  Буфер сбрасывается в RLM-движок как новый факт (L2).

## 3. HCO Cache (Semantic Block Cache)

**Проблема:** 44-ФЗ меняется часто, но 60% текста в новых редакциях дублируется.
**Решение:**
*   Для каждого блока текста вычисляется `sha256`.
*   Если хэш найден в SQLite (прошлая редакция), LLM-анализ (модальность, суммаризация) пропускается.
*   **Эффект:** Экономия 40-60% API-вызовов и сокращение времени парсинга в 2.5 раза.

## 4. TCGR (Temporal Causal Graph Reasoner)

Реализуется как надстройка над SQLite:
*   Каждая «изменяющая» статья (например, ст. 112) помечается как `parent` для изменяемой статьи.
*   При запросе RLM автоматически подтягивает всю «цепочку наследования» фактов через рекурсивные CTE-запросы в SQLite.

## 5. Готовность к эволюции (Future-Proofing)
Текущая иерархическая структура (L0-L3) спроектирована как входной слой для **Temporal Graph RAG Knowledge Base**.
*   **Парсер как агент:** Интерфейс библиотеки позволяет использовать LDUP как инструмент (`Tool`) в агентских фреймворках.
*   **Онтологический слой:** Извлеченные факты готовы к трансформации в графовые узлы с поддержкой NLP-модулей и автоматической генерацией схем.
